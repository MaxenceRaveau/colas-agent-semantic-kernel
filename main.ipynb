{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939e0148",
   "metadata": {},
   "source": [
    "# Installation des diff√©rents package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantic-kernel beautifulsoup4 python-dotenv google-cloud-bigquery pyyaml google-cloud-bigquery-storage python-docx ddgs google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c29d81",
   "metadata": {},
   "source": [
    "# Import des variables d'environnement\n",
    "\n",
    "Cette section charge les variables d'environnement depuis le fichier .env. Ces variables contiennent les cl√©s d'API et les identifiants n√©cessaires pour se connecter aux services Azure OpenAI, Google Cloud, etc.\n",
    "\n",
    "**Important :** N'oubliez pas de copier-coller le fichier .env √† la racine du code avec toutes les variables n√©cessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6736dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ea435",
   "metadata": {},
   "source": [
    "# Configuration des identifiants Google Cloud\n",
    "\n",
    "Cette cellule configure le chemin vers le fichier de compte de service Google Cloud. Ce fichier est requis pour s'authentifier aupr√®s des services Google Cloud comme BigQuery et Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"colas-training-service-account.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0606f",
   "metadata": {},
   "source": [
    "# Import des librairies n√©cessaires\n",
    "\n",
    "Cette cellule importe toutes les biblioth√®ques Python n√©cessaires pour le projet, incluant Semantic Kernel pour la cr√©ation d'agents IA, les connecteurs Azure OpenAI, les outils pour BigQuery, ainsi que les biblioth√®ques utilitaires pour le traitement de donn√©es et les requ√™tes HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "import logging\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "import yaml\n",
    "import os\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from typing import Annotated, Optional, List, Dict, Any\n",
    "from google.cloud import bigquery\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e203aaa2",
   "metadata": {},
   "source": [
    "# Cr√©ation de l'agent \"Example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436189f",
   "metadata": {},
   "source": [
    "## Tool M√©t√©o\n",
    "\n",
    "Cette section d√©finit le plugin m√©t√©o qui permet √† l'agent d'obtenir les conditions m√©t√©orologiques actuelles et les pr√©visions pour des coordonn√©es g√©ographiques sp√©cifiques. Le plugin utilise l'API Open-Meteo pour r√©cup√©rer les donn√©es de temp√©rature, humidit√©, vent et pr√©cipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherPlugin:\n",
    "    \"\"\"Weather plugin for Semantic Kernel with Open-Meteo API integration.\"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Fetches current weather for given coordinates using Open-Meteo API\"\n",
    "    )\n",
    "    def get_current_weather(\n",
    "        self,\n",
    "        latitude: float,\n",
    "        longitude: float\n",
    "    ) -> dict:\n",
    "        \"\"\"Fetches current weather for given coordinates.\n",
    "\n",
    "        Args:\n",
    "            latitude: Latitude coordinate\n",
    "            longitude: Longitude coordinate\n",
    "\n",
    "        Returns:\n",
    "            dict: Weather details with status\n",
    "        \"\"\"\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"current\": [\n",
    "                \"temperature_2m\",\n",
    "                \"relative_humidity_2m\",\n",
    "                \"precipitation\",\n",
    "                \"weather_code\",\n",
    "                \"wind_speed_10m\",\n",
    "            ],\n",
    "            \"timezone\": \"auto\",\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                return {\"status\": \"error\", \"error_message\": f\"API Error: {response.text}\"}\n",
    "\n",
    "            data = response.json()\n",
    "            current = data[\"current\"]\n",
    "\n",
    "            weather_description = self._get_weather_description(current[\"weather_code\"])\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"latitude\": data[\"latitude\"],\n",
    "                \"longitude\": data[\"longitude\"],\n",
    "                \"description\": weather_description,\n",
    "                \"temperature\": current[\"temperature_2m\"],\n",
    "                \"humidity\": current[\"relative_humidity_2m\"],\n",
    "                \"wind_speed\": current[\"wind_speed_10m\"],\n",
    "                \"precipitation_1h\": current[\"precipitation\"],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_weather_forecast\",\n",
    "        description=\"Fetches daily weather forecast for up to 16 days using Open-Meteo API\"\n",
    "    )\n",
    "    def get_weather_forecast(\n",
    "        self,\n",
    "        latitude: float,\n",
    "        longitude: float,\n",
    "        days: int = 7\n",
    "    ) -> dict:\n",
    "        \"\"\"Fetches daily weather forecast.\n",
    "\n",
    "        Args:\n",
    "            latitude: Latitude coordinate\n",
    "            longitude: Longitude coordinate\n",
    "            days: Number of days for forecast (default 7, max 16)\n",
    "\n",
    "        Returns:\n",
    "            dict: Forecast details with status\n",
    "        \"\"\"\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "        days = min(days, 16)\n",
    "\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"daily\": [\n",
    "                \"temperature_2m_max\",\n",
    "                \"temperature_2m_min\",\n",
    "                \"weather_code\",\n",
    "                \"precipitation_sum\",\n",
    "                \"wind_speed_10m_max\",\n",
    "                \"wind_gusts_10m_max\",\n",
    "                \"wind_direction_10m_dominant\",\n",
    "            ],\n",
    "            \"timezone\": \"auto\",\n",
    "            \"forecast_days\": days,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                return {\"status\": \"error\", \"error_message\": f\"API Error: {response.text}\"}\n",
    "\n",
    "            data = response.json()\n",
    "            daily = data[\"daily\"]\n",
    "\n",
    "            forecasts = []\n",
    "            for i in range(len(daily[\"time\"])):\n",
    "                weather_description = self._get_weather_description(daily[\"weather_code\"][i])\n",
    "                forecasts.append(\n",
    "                    {\n",
    "                        \"date\": daily[\"time\"][i],\n",
    "                        \"temp_max\": daily[\"temperature_2m_max\"][i],\n",
    "                        \"temp_min\": daily[\"temperature_2m_min\"][i],\n",
    "                        \"description\": weather_description,\n",
    "                        \"precipitation\": daily[\"precipitation_sum\"][i],\n",
    "                        \"wind_speed_max\": daily[\"wind_speed_10m_max\"][i],\n",
    "                        \"wind_gusts_max\": daily[\"wind_gusts_10m_max\"][i],\n",
    "                        \"wind_direction\": daily[\"wind_direction_10m_dominant\"][i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"latitude\": data[\"latitude\"],\n",
    "                \"longitude\": data[\"longitude\"],\n",
    "                \"forecasts\": forecasts,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_current_date\",\n",
    "        description=\"Fetches the current date and time\"\n",
    "    )\n",
    "    def get_current_date(self) -> dict:\n",
    "        \"\"\"Fetches the current date and time.\n",
    "\n",
    "        Returns:\n",
    "            dict: Current date and time with status\n",
    "        \"\"\"\n",
    "        try:\n",
    "            current_date_time = datetime.utcnow().isoformat()\n",
    "            return {\"status\": \"success\", \"current_date_time\": current_date_time}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": str(e)}\n",
    "\n",
    "    def _get_weather_description(self, code: int) -> str:\n",
    "        \"\"\"Maps WMO weather code to description.\n",
    "\n",
    "        Args:\n",
    "            code: WMO weather code\n",
    "\n",
    "        Returns:\n",
    "            str: Weather description\n",
    "        \"\"\"\n",
    "        weather_codes = {\n",
    "            0: \"clear sky\",\n",
    "            1: \"mainly clear\",\n",
    "            2: \"partly cloudy\",\n",
    "            3: \"overcast\",\n",
    "            45: \"fog\",\n",
    "            48: \"depositing rime fog\",\n",
    "            51: \"light drizzle\",\n",
    "            53: \"moderate drizzle\",\n",
    "            55: \"dense drizzle\",\n",
    "            56: \"light freezing drizzle\",\n",
    "            57: \"dense freezing drizzle\",\n",
    "            61: \"slight rain\",\n",
    "            63: \"moderate rain\",\n",
    "            65: \"heavy rain\",\n",
    "            66: \"light freezing rain\",\n",
    "            67: \"heavy freezing rain\",\n",
    "            71: \"slight snow\",\n",
    "            73: \"moderate snow\",\n",
    "            75: \"heavy snow\",\n",
    "            77: \"snow grains\",\n",
    "            80: \"slight rain showers\",\n",
    "            81: \"moderate rain showers\",\n",
    "            82: \"violent rain showers\",\n",
    "            85: \"slight snow showers\",\n",
    "            86: \"heavy snow showers\",\n",
    "            95: \"thunderstorm\",\n",
    "            96: \"thunderstorm with slight hail\",\n",
    "            99: \"thunderstorm with heavy hail\",\n",
    "        }\n",
    "        return weather_codes.get(code, \"unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db05a9a",
   "metadata": {},
   "source": [
    "## Tool Bigquery\n",
    "\n",
    "Cette section d√©finit le plugin BigQuery qui permet √† l'agent d'interroger la base de donn√©es BigQuery pour r√©cup√©rer des informations sur les chantiers. Le plugin peut ex√©cuter des requ√™tes SQL SELECT de mani√®re s√©curis√©e et retourner les r√©sultats au format JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41376cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from typing import Annotated, Optional\n",
    "from semantic_kernel.functions import kernel_function\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "\n",
    "class BigQueryPlugin:\n",
    "    \"\"\"\n",
    "    A simplified Semantic Kernel plugin for BigQuery table queries.\n",
    "    The agent determines the SQL query, executes it, and returns results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the BigQuery plugin.\n",
    "        Configured for table: colas-training.colas_data.data-chantier\n",
    "        \"\"\"\n",
    "        self.client = bigquery.Client(project=\"colas-training\")\n",
    "        self.project_id = \"colas-training\"\n",
    "        self.dataset_id = \"colas_data\"\n",
    "        self.table_name = \"data-chantier\"\n",
    "        self.full_table_id = f\"{self.project_id}.{self.dataset_id}.`{self.table_name}`\"\n",
    "        self.schema_cache = {}\n",
    "    \n",
    "    def _get_table_schema_yaml(self) -> str:\n",
    "        \"\"\"\n",
    "        Get table schema in YAML format for the agent to understand the table structure.\n",
    "        \"\"\"\n",
    "        if self.schema_cache:\n",
    "            return self.schema_cache.get('schema', '')\n",
    "        \n",
    "        try:\n",
    "            table_ref = f\"{self.project_id}.{self.dataset_id}.{self.table_name}\"\n",
    "            table = self.client.get_table(table_ref)\n",
    "            \n",
    "            schema_dict = {\n",
    "                'platform': 'BigQuery',\n",
    "                'project': self.project_id,\n",
    "                'dataset': self.dataset_id,\n",
    "                'table': self.table_name,\n",
    "                'full_path': f\"{self.project_id}.{self.dataset_id}.{self.table_name}\",\n",
    "                'description': table.description or 'Colas construction site data',\n",
    "                'columns': []\n",
    "            }\n",
    "            \n",
    "            for field in table.schema:\n",
    "                column_info = {\n",
    "                    'name': field.name,\n",
    "                    'type': field.field_type,\n",
    "                }\n",
    "                if field.description:\n",
    "                    column_info['description'] = field.description\n",
    "                schema_dict['columns'].append(column_info)\n",
    "            \n",
    "            yaml_schema = yaml.dump(schema_dict, default_flow_style=False)\n",
    "            self.schema_cache['schema'] = yaml_schema\n",
    "            return yaml_schema\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving schema: {str(e)}\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"get_table_schema\",\n",
    "        description=\"Gets the schema of the data-chantier table including column names, types, and descriptions. ALWAYS use this first to understand the table structure before creating a query.\"\n",
    "    )\n",
    "    async def get_table_schema(self) -> str:\n",
    "        \"\"\"Retrieve table schema so the agent can construct appropriate queries.\"\"\"\n",
    "        return self._get_table_schema_yaml()\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"execute_query\",\n",
    "        description=\"Executes a SQL SELECT query against the data-chantier table and returns the results. The table path is already configured as `colas-training.colas_data.data-chantier`.\"\n",
    "    )\n",
    "    async def execute_query(\n",
    "        self,\n",
    "        query: Annotated[str, \"The SQL SELECT query to execute. The table is available as `colas-training.colas_data.data-chantier` or you can use backticks for the table name with hyphens.\"],\n",
    "        max_results: Annotated[int, \"Maximum number of results to return. Default is 100.\"] = 100\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Execute a BigQuery SQL query and return results as JSON.\n",
    "        \"\"\"\n",
    "        # Security: Ensure query is SELECT only\n",
    "        query_upper = query.strip().upper()\n",
    "        if not query_upper.startswith('SELECT'):\n",
    "            return json.dumps({\n",
    "                'error': 'Only SELECT queries are allowed',\n",
    "                'row_count': 0,\n",
    "                'data': []\n",
    "            })\n",
    "        \n",
    "        # Prevent dangerous operations\n",
    "        dangerous_keywords = ['DROP', 'DELETE', 'INSERT', 'UPDATE', 'CREATE', 'ALTER', 'TRUNCATE']\n",
    "        if any(keyword in query_upper for keyword in dangerous_keywords):\n",
    "            return json.dumps({\n",
    "                'error': 'Query contains prohibited keywords. Only SELECT queries are allowed.',\n",
    "                'row_count': 0,\n",
    "                'data': []\n",
    "            })\n",
    "        \n",
    "        try:\n",
    "            query_job = self.client.query(query)\n",
    "            results = query_job.result(max_results=max_results)\n",
    "            \n",
    "            # Convert to list of dictionaries\n",
    "            rows = []\n",
    "            for row in results:\n",
    "                rows.append(dict(row))\n",
    "            \n",
    "            result_data = {\n",
    "                'row_count': len(rows),\n",
    "                'total_rows': results.total_rows,\n",
    "                'data': rows,\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "            return json.dumps(result_data, indent=2, default=str)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                'error': f\"Error executing query: {str(e)}\",\n",
    "                'row_count': 0,\n",
    "                'data': [],\n",
    "                'success': False\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ce52c",
   "metadata": {},
   "source": [
    "## Tool Date du Jour\n",
    "\n",
    "Cette section d√©finit le plugin de gestion des dates qui permet √† l'agent d'obtenir la date et l'heure actuelles dans le fuseau horaire de Paris. Cet outil est essentiel pour calculer les dates relatives (demain, apr√®s-demain, etc.) dans les requ√™tes utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb225816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class DateTimePlugin:\n",
    "    \"\"\"Plugin for fetching current date and time information.\"\"\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"get_current_date\",\n",
    "        description=\"Fetches the current date and time in Paris timezone\"\n",
    "    )\n",
    "    def get_current_date(self) -> dict:\n",
    "        \"\"\"Fetches the current date and time in Paris timezone.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary with 'status' and 'current_date_time'.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            current_date_time = datetime.now(ZoneInfo(\"Europe/Paris\")).isoformat()\n",
    "            return {\"status\": \"success\", \"current_date_time\": current_date_time}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dea728",
   "metadata": {},
   "source": [
    "## Chargement R√®gles M√©tier\n",
    "\n",
    "Cette section charge les r√®gles m√©tier depuis un document Word stock√© dans Google Cloud Storage. Ces r√®gles d√©finissent les crit√®res de faisabilit√© des travaux de chantier en fonction des conditions m√©t√©orologiques (temp√©rature, vent, pr√©cipitations). Les r√®gles sont ensuite int√©gr√©es dans le prompt de l'agent pour guider ses d√©cisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "from docx import Document\n",
    "import io\n",
    "\n",
    "def load_regles_chantier() -> str:\n",
    "    \"\"\"Load construction site rules from GCS document.\"\"\"\n",
    "    bucket_name = \"colas-data\"\n",
    "    source_blob_name = \"atelier-5-deepdive-gcp/crit√®res_travaux_formation_5_gcp.docx\"\n",
    "    service_account_file = \"colas-training-service-account.json\"\n",
    "    \n",
    "    try:\n",
    "        # Load credentials from service account JSON file\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            service_account_file\n",
    "        )\n",
    "        \n",
    "        storage_client = storage.Client(credentials=credentials)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(source_blob_name)\n",
    "        \n",
    "        in_memory_file = io.BytesIO()\n",
    "        blob.download_to_file(in_memory_file)\n",
    "        in_memory_file.seek(0)\n",
    "        \n",
    "        doc = Document(in_memory_file)\n",
    "        full_text = [para.text for para in doc.paragraphs]\n",
    "        return '\\n'.join(full_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading regles_chantier: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "regles_chantier = load_regles_chantier()\n",
    "print(regles_chantier[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f922be9",
   "metadata": {},
   "source": [
    "## Prompt de l'Agent\n",
    "\n",
    "Cette section d√©finit le prompt syst√®me de l'agent de faisabilit√© des chantiers. Le prompt d√©crit le r√¥le de l'agent, les actions qu'il doit effectuer (identification du chantier, requ√™te BigQuery, r√©cup√©ration m√©t√©o, √©valuation de faisabilit√©), et les r√®gles m√©tier √† appliquer. L'agent doit r√©pondre en fran√ßais avec des recommandations claires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55632739",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_prompt = f\"\"\"\n",
    "Role\n",
    "You are the Chantier Feasibility Agent, an expert system designed to determine the operational viability of construction sites (chantiers) based on their type, location, and weather forecast.\n",
    "Your main objective is to provide a clear, decisive, and actionable recommendation to the user regarding the feasibility of construction work on a requested date (within the next 7 days maximum).\n",
    "Your final response must always be in French.\n",
    "\n",
    "Actions\n",
    "You must execute the following sequence of actions to answer every user request:\n",
    "\n",
    "1. Identify Target and Date\n",
    "   - Determine the TYPE_chantier (or the Chef de Chantier if specified) and the requested date.\n",
    "   - **Date Calculation:** If the user provides a relative date (e.g., \"tomorrow,\" \"in 2 days,\" \"apr√®s-demain\"), you **MUST** call the `current_date_tool` to get today's date (November 7, 2025) and calculate the effective calendar date.\n",
    "   - The final, calculated date must be within the next 7 days from today (November 7, 2025).\n",
    "\n",
    "2. Query BigQuery (bigquery_tool)\n",
    "   - Search for records in colas-training.colas_data.data-chantier matching the requested TYPE_chantier or the NOM_chef_chantier / ID_chef_chantier.\n",
    "   - Possible outcomes:\n",
    "       * **Single chantier found:** proceed with that chantier.\n",
    "       * **Multiple chantiers found:** retrieve all matching chantiers (e.g., tous les chantiers g√©r√©s par le chef de chantier X) and process them individually.\n",
    "       * **No chantier found:** inform the user that no matching chantier exists in the database.\n",
    "\n",
    "3. Coordinate Processing\n",
    "   - For each chantier, COOR_chantier is formatted as a string \"latitude longitude\".\n",
    "   - Extract numeric values latitude and longitude to use them in the weather tool.\n",
    "\n",
    "4. Weather Query (open_weather_tool)\n",
    "   - For each chantier, use OpenWeatherApiTool to get weather data for its coordinates:\n",
    "     - **Future dates (up to 7 days)**: call `perform_action(latitude, longitude, action_type='forecast', days=7)`.\n",
    "     - **Today**: call `perform_action(latitude, longitude, action_type='current')`.\n",
    "   - Identify the forecast corresponding to the user's requested date.\n",
    "   - If the forecast for a chantier cannot be found, inform the user that the weather data is unavailable for that chantier.\n",
    "\n",
    "5. Determine Feasibility\n",
    "   - For each chantier, apply the feasibility rules (given below in French) to the obtained forecast data.\n",
    "   - Mapping for rule evaluation:\n",
    "       * Temp√©rature ‚Üí `temp_day` (¬∞C)\n",
    "       * Vent ‚Üí `wind_speed` (m/s)\n",
    "       * Pr√©cipitations ‚Üí if `desc` includes \"rain\" or \"shower\", treat as precipitation > 0 mm.\n",
    "   - Classify each chantier as one of three statuses:\n",
    "       ‚úÖ **FAISABLE** : toutes les conditions respectent les seuils.\n",
    "       ‚ö†Ô∏è **VIGILANT** : conditions limites ‚Äî chantier r√©alisable avec mesures de pr√©vention.\n",
    "       üö´ **NON FAISABLE** : au moins une condition d√©passe les seuils critiques.\n",
    "\n",
    "6. Safety & Prevention (for VIGILANT mode)\n",
    "   - If a chantier is in \"VIGILANT\" mode, provide relevant safety and prevention recommendations based on the weather risk:\n",
    "       * Vent fort ‚Üí s√©curiser le mat√©riel, limiter travail en hauteur.\n",
    "       * Temp√©rature basse ‚Üí pauses r√©guli√®res, √©quipement thermique adapt√©.\n",
    "       * Pluie ‚Üí prot√©ger le mat√©riel, planifier activit√©s sous abri.\n",
    "       * Chaleur √©lev√©e ‚Üí hydratation renforc√©e, travail aux heures fra√Æches.\n",
    "\n",
    "7. Final Response (in French)\n",
    "   - For each chantier, present a complete answer including:\n",
    "       * Le type de chantier\n",
    "       * La date demand√©e\n",
    "       * Les conditions m√©t√©o pertinentes (temp√©rature, vent, pr√©cipitation, etc.)\n",
    "       * Le verdict final : FAISABLE / VIGILANT / NON FAISABLE\n",
    "       * Si VIGILANT ‚Üí ajouter les r√®gles de pr√©vention/s√©curit√© adapt√©es.\n",
    "   - If multiple chantiers are requested, provide **individual results for each chantier** clearly separated.\n",
    "\n",
    "   - Example phrasing for multiple chantiers:\n",
    "       \"Chantier 1 - Toiture du 10 novembre : FAISABLE. Temp√©rature 9¬∞C, Vent 12 km/h, Pas de pr√©cipitation.\"\n",
    "       \"Chantier 2 - Peinture Ext√©rieure du 10 novembre : VIGILANT. Vent 28 km/h. Mesures recommand√©es : s√©curiser les √©chafaudages, limiter le travail en hauteur.\"\n",
    "       \"Chantier 3 - Fondations du 10 novembre : NON FAISABLE. Pluie mod√©r√©e pr√©vue (2 mm/h).\"\n",
    "\n",
    "Context\n",
    "\n",
    "BigQuery Table Structure\n",
    "The table accessible via bigquery_tool is: colas-training.colas_data.data-chantier\n",
    "Columns:\n",
    "- ID_chef_chantier\n",
    "- NOM_chef_chantier\n",
    "- COOR_chantier (format: \"latitude longitude\")\n",
    "- TYPE_chantier (e.g., Toiture, Fondations, Peinture Ext√©rieure)\n",
    "\n",
    "Feasibility Rules (Critical Operational Rules)\n",
    "The feasibility of a chantier is strictly governed by the following French thresholds.\n",
    "You must evaluate the weather data against these rules:\n",
    "{regles_chantier if regles_chantier else \"Rules not loaded. Please ensure regles_chantier is provided.\"}\n",
    "\n",
    "Constraints\n",
    "- Time Limit: Only dates ‚â§ 7 days from today (November 7, 2025) are allowed.\n",
    "- Unlisted Types: If the chantier type is not in the feasibility table, reply:\n",
    "  \"Les r√®gles de faisabilit√© pour ce type de chantier ne sont pas d√©finies dans mon contexte. Je ne peux pas √©valuer la viabilit√©.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a127b8",
   "metadata": {},
   "source": [
    "## Execution de l'agent\n",
    "\n",
    "Cette section contient la fonction principale qui initialise le kernel Semantic Kernel, configure les services Azure OpenAI, enregistre tous les plugins (BigQuery, M√©t√©o, Datetime), et d√©marre une boucle de conversation interactive. L'utilisateur peut poser des questions sur la faisabilit√© des chantiers et l'agent r√©pondra en utilisant les outils disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main():\n",
    "    # Initialize the kernel\n",
    "    kernel = Kernel()\n",
    "\n",
    "    # Add Azure OpenAI chat completion\n",
    "    chat_completion = AzureChatCompletion(\n",
    "        deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "        api_key=os.getenv(\"API_KEY\"),\n",
    "        base_url=os.getenv(\"BASE_URL\"),\n",
    "    )\n",
    "    kernel.add_service(chat_completion)\n",
    "\n",
    "    # Set up detailed logging for function calls\n",
    "    setup_logging()\n",
    "    \n",
    "    # Optional: Add console handler with formatting for better readability\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logging.getLogger(\"semantic_kernel\").addHandler(console_handler)\n",
    "\n",
    "    # Add BigQuery plugin\n",
    "    bq_plugin = BigQueryPlugin()\n",
    "    kernel.add_plugin(\n",
    "        bq_plugin,\n",
    "        plugin_name=\"BigQuery\"\n",
    "    )\n",
    "    kernel.add_plugin(\n",
    "    WeatherPlugin(),\n",
    "    plugin_name=\"Meteo\"\n",
    "    )\n",
    "    # Register the DateTime plugin\n",
    "    kernel.add_plugin(\n",
    "        DateTimePlugin(),\n",
    "        plugin_name=\"Datetime\"\n",
    "    )\n",
    "\n",
    "    # Enable planning\n",
    "    execution_settings = AzureChatPromptExecutionSettings()\n",
    "    execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "    # Create a history of the conversation\n",
    "    history = ChatHistory()\n",
    "\n",
    "    history.add_system_message(agent_prompt)\n",
    "\n",
    "    # Initiate a back-and-forth chat\n",
    "    userInput = None\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        userInput = input(\"User > \")\n",
    "\n",
    "        # Terminate the loop if the user says \"exit\"\n",
    "        if userInput == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Add user input to the history\n",
    "        history.add_user_message(userInput)\n",
    "\n",
    "        # Get the response from the AI\n",
    "        result = await chat_completion.get_chat_message_content(\n",
    "            chat_history=history,\n",
    "            settings=execution_settings,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Assistant > \" + str(result))\n",
    "\n",
    "        # Add the message from the agent to the chat history\n",
    "        history.add_message(result)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f25681",
   "metadata": {},
   "source": [
    "# Cr√©ation d'un Agent de A √† Z\n",
    "\n",
    "Cette section pr√©sente un nouveau projet : cr√©er un agent qui calcule le co√ªt en mat√©riaux pour r√©aliser une surface sp√©cifique. Le but de l'agent est de calculer le prix pour remplir une surface donn√©e avec un mat√©riau pr√©cis.\n",
    "\n",
    "**Exemple d'utilisation :** \"Combien √ßa va me co√ªter de couler du b√©ton sur 2 m√®tres de haut et 40 m√®tres de large ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8447c108",
   "metadata": {},
   "source": [
    "## Outils Math√©matiques\n",
    "\n",
    "Cette section doit contenir un plugin d'outils math√©matiques qui permettra √† l'agent d'effectuer les calculs n√©cessaires pour d√©terminer les volumes, surfaces et co√ªts des mat√©riaux. L'agent pourra ainsi calculer automatiquement les quantit√©s de mat√©riaux n√©cessaires en fonction des dimensions fournies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclure votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6563ab",
   "metadata": {},
   "source": [
    "## Outils Recherche Web ( Google )\n",
    "\n",
    "Cette section d√©finit le plugin de recherche web utilisant DuckDuckGo. Cet outil permet √† l'agent de rechercher sur internet les prix actuels des mat√©riaux de construction. Le plugin peut effectuer des recherches rapides ou r√©cup√©rer le contenu complet des pages web pour extraire les informations de prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "class GoogleSearchPlugin:\n",
    "    def __init__(self, api_key: str, cx: str):\n",
    "        self.api_key = api_key\n",
    "        self.cx = cx\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"search\",\n",
    "        description=\"Search the web using Google Custom Search\"\n",
    "    )\n",
    "    def search(self, query: str, max_results: int = 10) -> str:\n",
    "        url = (\n",
    "            \"https://www.googleapis.com/customsearch/v1\"\n",
    "            f\"?key={self.api_key}&cx={self.cx}\"\n",
    "            f\"&q={query}&num={max_results}\"\n",
    "        )\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        items = data.get(\"items\", [])\n",
    "        if not items:\n",
    "            return \"No results found.\"\n",
    "\n",
    "        lines = []\n",
    "        for item in items:\n",
    "            title = item.get('title')\n",
    "            snippet = item.get('snippet')\n",
    "            link = item.get('link')\n",
    "            \n",
    "            # Retry logic for 403 errors\n",
    "            max_retries = 5\n",
    "            retry_count = 0\n",
    "            link_content = \"Error fetching the content\"\n",
    "            \n",
    "            while retry_count < max_retries:\n",
    "                try:\n",
    "                    headers = {\n",
    "                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "                    }\n",
    "                    link_resp = requests.get(link, headers=headers, timeout=10)\n",
    "                    \n",
    "                    if link_resp.status_code == 403:\n",
    "                        retry_count += 1\n",
    "                        time.sleep(1)  # Wait before retrying\n",
    "                        continue\n",
    "                    \n",
    "                    link_resp.raise_for_status()\n",
    "                    link_content = link_resp.text[:5000]\n",
    "                    break  # Success, exit retry loop\n",
    "                    \n",
    "                except requests.RequestException as e:\n",
    "                    if retry_count < max_retries - 1:\n",
    "                        retry_count += 1\n",
    "                        time.sleep(1)\n",
    "                    else:\n",
    "                        link_content = f\"Error fetching the content: {str(e)}\"\n",
    "                        break\n",
    "            \n",
    "            lines.append(\n",
    "                f\"- {title}\\n  {snippet}\\n  {link}\\n  Content Preview: {link_content}\\n\"\n",
    "            )\n",
    "\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d954470",
   "metadata": {},
   "source": [
    "## Outils Recherche Web ( DuckDuckGo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import kernel_function\n",
    "from ddgs import DDGS\n",
    "from ddgs.exceptions import DDGSException, RatelimitException, TimeoutException\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class DuckDuckGoSearchPlugin:\n",
    "    \"\"\"Custom DuckDuckGo search plugin with webpage content fetching using ddgs library\"\"\"\n",
    "    \n",
    "    def __init__(self, proxy: Optional[str] = None, timeout: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize the plugin with ddgs library\n",
    "        \n",
    "        Args:\n",
    "            proxy: Optional proxy string (e.g., \"socks5h://127.0.0.1:9150\" or \"tb\" for Tor Browser)\n",
    "            timeout: Timeout for requests (default: 10)\n",
    "        \"\"\"\n",
    "        self.proxy = proxy\n",
    "        self.timeout = timeout\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"search_and_fetch\",\n",
    "        description=\"Search the web using DuckDuckGo and fetch full content from top results\"\n",
    "    )\n",
    "    async def search_and_fetch(\n",
    "        self,\n",
    "        query: str,\n",
    "        num_results: int = 3,\n",
    "        max_chars_per_page: int = 5000,\n",
    "        region: str = \"us-en\",\n",
    "        safesearch: str = \"moderate\",\n",
    "        backend: str = \"auto\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Search DuckDuckGo and fetch actual webpage content\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            num_results: Number of results to fetch (default: 3)\n",
    "            max_chars_per_page: Maximum characters per page (default: 5000)\n",
    "            region: Region code (default: us-en)\n",
    "            safesearch: Safe search setting (on/moderate/off, default: moderate)\n",
    "            backend: Search backend (default: auto, options: bing, brave, google, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            Formatted search results with full content\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Step 1: Get search results from DuckDuckGo using ddgs\n",
    "            ddgs = DDGS(proxy=self.proxy, timeout=self.timeout)\n",
    "            search_results = ddgs.text(\n",
    "                query=query,\n",
    "                region=region,\n",
    "                safesearch=safesearch,\n",
    "                max_results=num_results,\n",
    "                page=1,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            if not search_results:\n",
    "                return \"No results found\"\n",
    "            \n",
    "            # Step 2: Fetch content from each webpage\n",
    "            results = []\n",
    "            \n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                for i, result in enumerate(search_results, 1):\n",
    "                    title = result.get('title', 'No title')\n",
    "                    link = result.get('href', '')\n",
    "                    snippet = result.get('body', 'No description')\n",
    "                    \n",
    "                    # Fetch the actual webpage\n",
    "                    try:\n",
    "                        headers = {\n",
    "                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "                        }\n",
    "                        \n",
    "                        async with session.get(\n",
    "                            link,\n",
    "                            timeout=aiohttp.ClientTimeout(total=10),\n",
    "                            headers=headers,\n",
    "                            ssl=False  # Skip SSL verification for problematic sites\n",
    "                        ) as response:\n",
    "                            if response.status == 200:\n",
    "                                html = await response.text()\n",
    "                                \n",
    "                                # Parse HTML and extract text\n",
    "                                soup = BeautifulSoup(html, 'html.parser')\n",
    "                                \n",
    "                                # Remove unwanted elements\n",
    "                                for element in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']):\n",
    "                                    element.decompose()\n",
    "                                \n",
    "                                # Get text content\n",
    "                                text = soup.get_text(separator=' ', strip=True)\n",
    "                                \n",
    "                                # Clean up whitespace\n",
    "                                lines = (line.strip() for line in text.splitlines())\n",
    "                                text = ' '.join(line for line in lines if line)\n",
    "                                \n",
    "                                # Truncate if too long\n",
    "                                if len(text) > max_chars_per_page:\n",
    "                                    text = text[:max_chars_per_page] + \"...\"\n",
    "                                \n",
    "                                results.append(\n",
    "                                    f\"Result {i}:\\n\"\n",
    "                                    f\"Title: {title}\\n\"\n",
    "                                    f\"URL: {link}\\n\"\n",
    "                                    f\"Snippet: {snippet}\\n\\n\"\n",
    "                                    f\"Full Content:\\n{text}\"\n",
    "                                )\n",
    "                            else:\n",
    "                                results.append(\n",
    "                                    f\"Result {i}:\\n\"\n",
    "                                    f\"Title: {title}\\n\"\n",
    "                                    f\"URL: {link}\\n\"\n",
    "                                    f\"Snippet: {snippet}\\n\"\n",
    "                                    f\"Note: Could not fetch content (HTTP {response.status})\"\n",
    "                                )\n",
    "                    except Exception as e:\n",
    "                        results.append(\n",
    "                            f\"Result {i}:\\n\"\n",
    "                            f\"Title: {title}\\n\"\n",
    "                            f\"URL: {link}\\n\"\n",
    "                            f\"Snippet: {snippet}\\n\"\n",
    "                            f\"Note: Error fetching content - {str(e)}\"\n",
    "                        )\n",
    "            \n",
    "            return \"\\n\\n\" + (\"=\"*80 + \"\\n\\n\").join(results)\n",
    "            \n",
    "        except (DDGSException, RatelimitException, TimeoutException) as e:\n",
    "            return f\"Search error: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return f\"Unexpected error: {str(e)}\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"quick_search\",\n",
    "        description=\"Quick web search using DuckDuckGo (returns only titles and snippets, faster)\"\n",
    "    )\n",
    "    def quick_search(\n",
    "        self,\n",
    "        query: str,\n",
    "        num_results: int = 5,\n",
    "        region: str = \"us-en\",\n",
    "        safesearch: str = \"moderate\",\n",
    "        backend: str = \"auto\",\n",
    "        timelimit: Optional[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Quick search without fetching full content (synchronous)\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            num_results: Number of results (default: 5)\n",
    "            region: Region code (default: us-en)\n",
    "            safesearch: Safe search setting (default: moderate)\n",
    "            backend: Search backend (default: auto)\n",
    "            timelimit: Time limit for results: d (day), w (week), m (month), y (year). Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            Formatted search results with titles and snippets only\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ddgs = DDGS(proxy=self.proxy, timeout=self.timeout)\n",
    "            search_results = ddgs.text(\n",
    "                query=query,\n",
    "                region=region,\n",
    "                safesearch=safesearch,\n",
    "                timelimit=timelimit,\n",
    "                max_results=num_results,\n",
    "                page=1,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            if not search_results:\n",
    "                return \"No results found\"\n",
    "            \n",
    "            results = []\n",
    "            for i, result in enumerate(search_results, 1):\n",
    "                title = result.get('title', 'No title')\n",
    "                link = result.get('href', '')\n",
    "                snippet = result.get('body', 'No description')\n",
    "                \n",
    "                results.append(\n",
    "                    f\"{i}. {title}\\n\"\n",
    "                    f\"URL: {link}\\n\"\n",
    "                    f\"Snippet: {snippet}\"\n",
    "                )\n",
    "            \n",
    "            return \"\\n\\n\".join(results)\n",
    "            \n",
    "        except (DDGSException, RatelimitException, TimeoutException) as e:\n",
    "            return f\"Search error: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return f\"Unexpected error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050211c",
   "metadata": {},
   "source": [
    "## Cr√©ation du prompt de l'agent\n",
    "\n",
    "Cette section doit contenir le prompt syst√®me pour l'agent de calcul de co√ªts. Le prompt doit d√©finir le r√¥le de l'agent, expliquer comment il doit utiliser les outils math√©matiques pour calculer les volumes/surfaces, rechercher les prix des mat√©riaux sur le web, et fournir une estimation de co√ªt finale √† l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c342f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_prompt = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821ee96",
   "metadata": {},
   "source": [
    "## D√©finition de la boucle pour int√©ragir avec les agents\n",
    "\n",
    "Cette section doit contenir le code de la boucle d'interaction avec l'agent de calcul de co√ªts. Similaire √† la boucle de l'agent de faisabilit√©, elle initialise le kernel, enregistre les plugins (math√©matiques et recherche web), et permet une conversation interactive o√π l'utilisateur peut demander des estimations de co√ªts pour diff√©rents projets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclure votre code ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01295377",
   "metadata": {},
   "source": [
    "# Bonus, inclure un MCP √† l'agent\n",
    "\n",
    "\n",
    "Cette section est un exercice bonus pour int√©grer un MCP (Model Context Protocol) √† l'agent. Le MCP permet d'√©tendre les capacit√©s de l'agent en lui donnant acc√®s √† des outils et contextes suppl√©mentaires via un protocole standardis√©.\n",
    "\n",
    "**Amusez-vous bien !** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6855a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fa2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
