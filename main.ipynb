{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939e0148",
   "metadata": {},
   "source": [
    "# Installation des différents package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f8bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting semantic-kernel\n",
      "  Downloading semantic_kernel-1.38.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.34.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
      "Collecting google-cloud-bigquery-storage\n",
      "  Downloading google_cloud_bigquery_storage-2.34.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting azure-ai-projects>=1.0.0b12 (from semantic-kernel)\n",
      "  Downloading azure_ai_projects-2.0.0b2-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-ai-agents>=1.2.0b3 (from semantic-kernel)\n",
      "  Downloading azure_ai_agents-1.2.0b6-py3-none-any.whl.metadata (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp~=3.8 (from semantic-kernel)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cloudevents~=1.0 (from semantic-kernel)\n",
      "  Downloading cloudevents-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (2.11.7)\n",
      "Collecting pydantic-settings~=2.0 (from semantic-kernel)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting defusedxml~=0.7 (from semantic-kernel)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting azure-identity>=1.13 (from semantic-kernel)\n",
      "  Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (2.1.3)\n",
      "Collecting openai<2,>=1.98.0 (from semantic-kernel)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
      "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: websockets<16,>=13 in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (15.0.1)\n",
      "Collecting aiortc>=1.9.0 (from semantic-kernel)\n",
      "  Downloading aiortc-1.14.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (1.34.1)\n",
      "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prance<25.4.9,>=23.6.21 (from semantic-kernel)\n",
      "  Downloading prance-25.4.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybars4~=0.9 (from semantic-kernel)\n",
      "  Downloading pybars4-0.9.13.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2~=3.1 in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/mraveau1/.local/lib/python3.12/site-packages (from semantic-kernel) (1.6.0)\n",
      "Collecting scipy>=1.15.1 (from semantic-kernel)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (5.29.5)\n",
      "Requirement already satisfied: typing-extensions>=4.13 in /usr/local/lib/python3.12/dist-packages (from semantic-kernel) (4.14.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.40.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (25.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery-storage) (1.73.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery-storage) (1.26.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aioice<1.0.0,>=0.10.1 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading aioice-0.10.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting av<17.0.0,>=14.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in /usr/local/lib/python3.12/dist-packages (from aiortc>=1.9.0->semantic-kernel) (45.0.5)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in /usr/local/lib/python3.12/dist-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
      "Collecting pyee>=13.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pylibsrtp>=0.10.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pyopenssl>=25.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-agents>=1.2.0b3->semantic-kernel)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-core>=1.30.0 (from azure-ai-agents>=1.2.0b3->semantic-kernel)\n",
      "  Downloading azure_core-1.36.0-py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-storage-blob>=12.15.0 (from azure-ai-projects>=1.0.0b12->semantic-kernel)\n",
      "  Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity>=1.13->semantic-kernel)\n",
      "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity>=1.13->semantic-kernel)\n",
      "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting deprecation<3.0,>=2.0 (from cloudevents~=1.0->semantic-kernel)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.98.0->semantic-kernel) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2,>=1.98.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.98.0->semantic-kernel) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2,>=1.98.0->semantic-kernel)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.98.0->semantic-kernel) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2,>=1.98.0->semantic-kernel)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.24.0)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.7.0)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting werkzeug<3.1.2 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.7.0)\n",
      "Collecting opentelemetry-api~=1.24 (from semantic-kernel)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk~=1.24->semantic-kernel)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting chardet>=5.2 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting ruamel.yaml>=0.18.10 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel)\n",
      "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.7.9)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (2.7.0)\n",
      "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in /usr/local/lib/python3.12/dist-packages (from cryptography>=44.0.0->aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.26.0)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/lib/python3/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.7.0)\n",
      "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
      "Collecting cryptography>=44.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.0.0 (from pylibsrtp>=0.10.0->aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->pylibsrtp>=0.10.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
      "Downloading semantic_kernel-1.38.0-py3-none-any.whl (894 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.8/894.8 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading google_cloud_bigquery_storage-2.34.0-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiortc-1.14.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_ai_agents-1.2.0b6-py3-none-any.whl (217 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_ai_projects-2.0.0b2-py3-none-any.whl (234 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.0/234.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.25.1-py3-none-any.whl (191 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.3/191.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudevents-1.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m416.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prance-25.4.8.0-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aioice-0.10.1-py3-none-any.whl (24 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.36.0-py3-none-any.whl (213 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.3/213.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_storage_blob-12.27.1-py3-none-any.whl (428 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m429.0/429.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Building wheels for collected packages: pybars4, PyMeta3\n",
      "  Building wheel for pybars4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14419 sha256=1df44af145c538e1e5ef9f425567abf7ec824f76591c624002134367c749c958\n",
      "  Stored in directory: /home/mraveau1/.cache/pip/wheels/75/2d/da/c75b2fc7b00dc9c154dff65f689a318e7d24b44c612c2b21f1\n",
      "  Building wheel for PyMeta3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMeta3: filename=pymeta3-0.5.1-py3-none-any.whl size=16519 sha256=bbfd18cb85393694e601e24e9212c97cf55f48adeed9bfd8f2da46a384899f8e\n",
      "  Stored in directory: /home/mraveau1/.cache/pip/wheels/5a/9b/2c/81b7551d2c05a482817e6c3b3d2f8ad2a0229db874c4bc6346\n",
      "Successfully built pybars4 PyMeta3\n",
      "Installing collected packages: PyMeta3, parse, ifaddr, werkzeug, tqdm, scipy, ruamel.yaml.clib, rfc3339-validator, python-dotenv, pyee, pybars4, propcache, pathable, multidict, lazy-object-proxy, jiter, isodate, frozenlist, deprecation, defusedxml, chardet, cffi, av, aioice, aiohappyeyeballs, yarl, ruamel.yaml, pylibsrtp, opentelemetry-api, jsonschema-path, cryptography, cloudevents, azure-core, aiosignal, pyopenssl, pydantic-settings, prance, opentelemetry-semantic-conventions, openai, azure-storage-blob, azure-ai-agents, aiohttp, opentelemetry-sdk, openapi-schema-validator, msal, azure-ai-projects, aiortc, openapi-spec-validator, msal-extensions, google-cloud-bigquery-storage, openapi_core, azure-identity, semantic-kernel\n",
      "Successfully installed PyMeta3-0.5.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aioice-0.10.1 aiortc-1.14.0 aiosignal-1.4.0 av-16.0.1 azure-ai-agents-1.2.0b6 azure-ai-projects-2.0.0b2 azure-core-1.36.0 azure-identity-1.25.1 azure-storage-blob-12.27.1 cffi-2.0.0 chardet-5.2.0 cloudevents-1.12.0 cryptography-46.0.3 defusedxml-0.7.1 deprecation-2.1.0 frozenlist-1.8.0 google-cloud-bigquery-storage-2.34.0 ifaddr-0.2.0 isodate-0.7.2 jiter-0.12.0 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 msal-1.34.0 msal-extensions-1.3.1 multidict-6.7.0 openai-1.109.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 openapi_core-0.19.5 opentelemetry-api-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 parse-1.20.2 pathable-0.4.4 prance-25.4.8.0 propcache-0.4.1 pybars4-0.9.13 pydantic-settings-2.12.0 pyee-13.0.0 pylibsrtp-1.0.0 pyopenssl-25.3.0 python-dotenv-1.2.1 rfc3339-validator-0.1.4 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.15 scipy-1.16.3 semantic-kernel-1.38.0 tqdm-4.67.1 werkzeug-3.1.1 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install semantic-kernel python-dotenv google-cloud-bigquery pyyaml google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c29d81",
   "metadata": {},
   "source": [
    "# Import des variables d'environnement\n",
    "\n",
    "N'oubliez pas de copier-coller le fichier .env à la racine du code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6736dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4287e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/service-account-key.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"colas-training-service-account.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0606f",
   "metadata": {},
   "source": [
    "# Import des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bedc7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "import logging\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "import yaml\n",
    "import os\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from typing import Annotated, Optional, List, Dict, Any\n",
    "from google.cloud import bigquery\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436189f",
   "metadata": {},
   "source": [
    "# Définition du Tool permettant de récupérer la météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4381e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherPlugin:\n",
    "    \"\"\"Weather plugin for Semantic Kernel with Open-Meteo API integration.\"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Fetches current weather for given coordinates using Open-Meteo API\"\n",
    "    )\n",
    "    def get_current_weather(\n",
    "        self,\n",
    "        latitude: float,\n",
    "        longitude: float\n",
    "    ) -> dict:\n",
    "        \"\"\"Fetches current weather for given coordinates.\n",
    "\n",
    "        Args:\n",
    "            latitude: Latitude coordinate\n",
    "            longitude: Longitude coordinate\n",
    "\n",
    "        Returns:\n",
    "            dict: Weather details with status\n",
    "        \"\"\"\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"current\": [\n",
    "                \"temperature_2m\",\n",
    "                \"relative_humidity_2m\",\n",
    "                \"precipitation\",\n",
    "                \"weather_code\",\n",
    "                \"wind_speed_10m\",\n",
    "            ],\n",
    "            \"timezone\": \"auto\",\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                return {\"status\": \"error\", \"error_message\": f\"API Error: {response.text}\"}\n",
    "\n",
    "            data = response.json()\n",
    "            current = data[\"current\"]\n",
    "\n",
    "            weather_description = self._get_weather_description(current[\"weather_code\"])\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"latitude\": data[\"latitude\"],\n",
    "                \"longitude\": data[\"longitude\"],\n",
    "                \"description\": weather_description,\n",
    "                \"temperature\": current[\"temperature_2m\"],\n",
    "                \"humidity\": current[\"relative_humidity_2m\"],\n",
    "                \"wind_speed\": current[\"wind_speed_10m\"],\n",
    "                \"precipitation_1h\": current[\"precipitation\"],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_weather_forecast\",\n",
    "        description=\"Fetches daily weather forecast for up to 16 days using Open-Meteo API\"\n",
    "    )\n",
    "    def get_weather_forecast(\n",
    "        self,\n",
    "        latitude: float,\n",
    "        longitude: float,\n",
    "        days: int = 7\n",
    "    ) -> dict:\n",
    "        \"\"\"Fetches daily weather forecast.\n",
    "\n",
    "        Args:\n",
    "            latitude: Latitude coordinate\n",
    "            longitude: Longitude coordinate\n",
    "            days: Number of days for forecast (default 7, max 16)\n",
    "\n",
    "        Returns:\n",
    "            dict: Forecast details with status\n",
    "        \"\"\"\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "        days = min(days, 16)\n",
    "\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"daily\": [\n",
    "                \"temperature_2m_max\",\n",
    "                \"temperature_2m_min\",\n",
    "                \"weather_code\",\n",
    "                \"precipitation_sum\",\n",
    "                \"wind_speed_10m_max\",\n",
    "                \"wind_gusts_10m_max\",\n",
    "                \"wind_direction_10m_dominant\",\n",
    "            ],\n",
    "            \"timezone\": \"auto\",\n",
    "            \"forecast_days\": days,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                return {\"status\": \"error\", \"error_message\": f\"API Error: {response.text}\"}\n",
    "\n",
    "            data = response.json()\n",
    "            daily = data[\"daily\"]\n",
    "\n",
    "            forecasts = []\n",
    "            for i in range(len(daily[\"time\"])):\n",
    "                weather_description = self._get_weather_description(daily[\"weather_code\"][i])\n",
    "                forecasts.append(\n",
    "                    {\n",
    "                        \"date\": daily[\"time\"][i],\n",
    "                        \"temp_max\": daily[\"temperature_2m_max\"][i],\n",
    "                        \"temp_min\": daily[\"temperature_2m_min\"][i],\n",
    "                        \"description\": weather_description,\n",
    "                        \"precipitation\": daily[\"precipitation_sum\"][i],\n",
    "                        \"wind_speed_max\": daily[\"wind_speed_10m_max\"][i],\n",
    "                        \"wind_gusts_max\": daily[\"wind_gusts_10m_max\"][i],\n",
    "                        \"wind_direction\": daily[\"wind_direction_10m_dominant\"][i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"latitude\": data[\"latitude\"],\n",
    "                \"longitude\": data[\"longitude\"],\n",
    "                \"forecasts\": forecasts,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_current_date\",\n",
    "        description=\"Fetches the current date and time\"\n",
    "    )\n",
    "    def get_current_date(self) -> dict:\n",
    "        \"\"\"Fetches the current date and time.\n",
    "\n",
    "        Returns:\n",
    "            dict: Current date and time with status\n",
    "        \"\"\"\n",
    "        try:\n",
    "            current_date_time = datetime.utcnow().isoformat()\n",
    "            return {\"status\": \"success\", \"current_date_time\": current_date_time}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"error_message\": str(e)}\n",
    "\n",
    "    def _get_weather_description(self, code: int) -> str:\n",
    "        \"\"\"Maps WMO weather code to description.\n",
    "\n",
    "        Args:\n",
    "            code: WMO weather code\n",
    "\n",
    "        Returns:\n",
    "            str: Weather description\n",
    "        \"\"\"\n",
    "        weather_codes = {\n",
    "            0: \"clear sky\",\n",
    "            1: \"mainly clear\",\n",
    "            2: \"partly cloudy\",\n",
    "            3: \"overcast\",\n",
    "            45: \"fog\",\n",
    "            48: \"depositing rime fog\",\n",
    "            51: \"light drizzle\",\n",
    "            53: \"moderate drizzle\",\n",
    "            55: \"dense drizzle\",\n",
    "            56: \"light freezing drizzle\",\n",
    "            57: \"dense freezing drizzle\",\n",
    "            61: \"slight rain\",\n",
    "            63: \"moderate rain\",\n",
    "            65: \"heavy rain\",\n",
    "            66: \"light freezing rain\",\n",
    "            67: \"heavy freezing rain\",\n",
    "            71: \"slight snow\",\n",
    "            73: \"moderate snow\",\n",
    "            75: \"heavy snow\",\n",
    "            77: \"snow grains\",\n",
    "            80: \"slight rain showers\",\n",
    "            81: \"moderate rain showers\",\n",
    "            82: \"violent rain showers\",\n",
    "            85: \"slight snow showers\",\n",
    "            86: \"heavy snow showers\",\n",
    "            95: \"thunderstorm\",\n",
    "            96: \"thunderstorm with slight hail\",\n",
    "            99: \"thunderstorm with heavy hail\",\n",
    "        }\n",
    "        return weather_codes.get(code, \"unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db05a9a",
   "metadata": {},
   "source": [
    "# Tool Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41376cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigQueryPlugin:\n",
    "    \"\"\"\n",
    "    A Semantic Kernel plugin for intelligent BigQuery table access.\n",
    "    Automatically determines which queries to create based on user requests.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_id: str, dataset_id: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the BigQuery plugin.\n",
    "        \n",
    "        Args:\n",
    "            project_id: Google Cloud project ID\n",
    "            dataset_id: Default dataset ID (optional)\n",
    "        \"\"\"\n",
    "        self.client = bigquery.Client(project=project_id)\n",
    "        self.project_id = project_id\n",
    "        self.dataset_id = dataset_id\n",
    "        self.schema_cache = {}\n",
    "        \n",
    "    def _get_table_schema_yaml(self, table_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Get table schema in YAML format for LLM consumption.\n",
    "        Uses YAML for token efficiency as recommended by Semantic Kernel best practices.\n",
    "        \"\"\"\n",
    "        if table_id in self.schema_cache:\n",
    "            return self.schema_cache[table_id]\n",
    "        \n",
    "        try:\n",
    "            table_ref = f\"{self.project_id}.{table_id}\"\n",
    "            table = self.client.get_table(table_ref)\n",
    "            \n",
    "            schema_dict = {\n",
    "                'platform': 'BigQuery',\n",
    "                'table': table_id,\n",
    "                'description': table.description or f'Table {table_id}',\n",
    "                'columns': []\n",
    "            }\n",
    "            \n",
    "            for field in table.schema:\n",
    "                column_info = {\n",
    "                    'name': field.name,\n",
    "                    'type': field.field_type,\n",
    "                }\n",
    "                if field.description:\n",
    "                    column_info['description'] = field.description\n",
    "                schema_dict['columns'].append(column_info)\n",
    "            \n",
    "            yaml_schema = yaml.dump(schema_dict, default_flow_style=False)\n",
    "            self.schema_cache[table_id] = yaml_schema\n",
    "            return yaml_schema\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving schema: {str(e)}\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"get_table_schema\",\n",
    "        description=\"Gets the schema of a BigQuery table including column names, types, and descriptions. Use this to understand table structure before querying.\"\n",
    "    )\n",
    "    async def get_table_schema(\n",
    "        self,\n",
    "        table_id: Annotated[str, \"The table ID in format 'dataset.table' or 'project.dataset.table'\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Retrieve table schema in YAML format.\"\"\"\n",
    "        return self._get_table_schema_yaml(table_id)\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"list_tables\",\n",
    "        description=\"Lists all tables in a dataset. Use this when you need to discover available tables or when the user asks about what data is available.\"\n",
    "    )\n",
    "    async def list_tables(\n",
    "        self,\n",
    "        dataset_id: Annotated[Optional[str], \"The dataset ID. If not provided, uses the default dataset\"] = None\n",
    "    ) -> str:\n",
    "        \"\"\"List all tables in the specified dataset.\"\"\"\n",
    "        target_dataset = dataset_id or self.dataset_id\n",
    "        \n",
    "        if not target_dataset:\n",
    "            return \"Error: No dataset specified and no default dataset configured\"\n",
    "        \n",
    "        try:\n",
    "            dataset_ref = f\"{self.project_id}.{target_dataset}\"\n",
    "            tables = self.client.list_tables(dataset_ref)\n",
    "            \n",
    "            table_list = []\n",
    "            for table in tables:\n",
    "                table_info = {\n",
    "                    'table_id': table.table_id,\n",
    "                    'full_table_id': f\"{target_dataset}.{table.table_id}\",\n",
    "                    'table_type': table.table_type\n",
    "                }\n",
    "                table_list.append(table_info)\n",
    "            \n",
    "            return json.dumps(table_list, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error listing tables: {str(e)}\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"execute_query\",\n",
    "        description=\"Executes a SQL query against BigQuery. The query should be a valid BigQuery SQL SELECT statement. Use this only after understanding the table schema. Always use fully qualified table names (dataset.table).\"\n",
    "    )\n",
    "    async def execute_query(\n",
    "        self,\n",
    "        query: Annotated[str, \"The SQL SELECT query to execute. Must be a valid BigQuery SQL statement with fully qualified table names.\"],\n",
    "        max_results: Annotated[int, \"Maximum number of results to return. Default is 100.\"] = 100\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Execute a BigQuery SQL query and return results.\n",
    "        Implements read-only access for security.\n",
    "        \"\"\"\n",
    "        # Security: Ensure query is SELECT only\n",
    "        query_upper = query.strip().upper()\n",
    "        if not query_upper.startswith('SELECT'):\n",
    "            return \"Error: Only SELECT queries are allowed for security reasons\"\n",
    "        \n",
    "        # Prevent potentially dangerous operations\n",
    "        dangerous_keywords = ['DROP', 'DELETE', 'INSERT', 'UPDATE', 'CREATE', 'ALTER', 'TRUNCATE']\n",
    "        if any(keyword in query_upper for keyword in dangerous_keywords):\n",
    "            return f\"Error: Query contains prohibited keywords. Only SELECT queries are allowed.\"\n",
    "        \n",
    "        try:\n",
    "            query_job = self.client.query(query)\n",
    "            results = query_job.result(max_results=max_results)\n",
    "            \n",
    "            # Convert to list of dictionaries\n",
    "            rows = []\n",
    "            for row in results:\n",
    "                rows.append(dict(row))\n",
    "            \n",
    "            result_data = {\n",
    "                'row_count': len(rows),\n",
    "                'total_rows': results.total_rows,\n",
    "                'data': rows[:max_results]\n",
    "            }\n",
    "            \n",
    "            return json.dumps(result_data, indent=2, default=str)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error executing query: {str(e)}\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"validate_query\",\n",
    "        description=\"Validates a SQL query without executing it. Use this to check if a query is syntactically correct before execution.\"\n",
    "    )\n",
    "    async def validate_query(\n",
    "        self,\n",
    "        query: Annotated[str, \"The SQL query to validate\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Validate a query using BigQuery dry run.\"\"\"\n",
    "        try:\n",
    "            job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "            query_job = self.client.query(query, job_config=job_config)\n",
    "            \n",
    "            return json.dumps({\n",
    "                'valid': True,\n",
    "                'total_bytes_processed': query_job.total_bytes_processed,\n",
    "                'message': 'Query is valid'\n",
    "            }, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                'valid': False,\n",
    "                'error': str(e)\n",
    "            }, indent=2)\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"get_table_preview\",\n",
    "        description=\"Gets a preview of table data (first 10 rows). Use this to understand the actual data in a table.\"\n",
    "    )\n",
    "    async def get_table_preview(\n",
    "        self,\n",
    "        table_id: Annotated[str, \"The table ID in format 'dataset.table'\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Get a preview of table data.\"\"\"\n",
    "        query = f\"SELECT * FROM `{self.project_id}.{table_id}` LIMIT 10\"\n",
    "        return await self.execute_query(query, max_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main():\n",
    "    # Initialize the kernel\n",
    "    kernel = Kernel()\n",
    "\n",
    "    # Add Azure OpenAI chat completion\n",
    "    chat_completion = AzureChatCompletion(\n",
    "        deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "        api_key=os.getenv(\"API_KEY\"),\n",
    "        base_url=os.getenv(\"BASE_URL\"),\n",
    "    )\n",
    "    kernel.add_service(chat_completion)\n",
    "\n",
    "    # Set the logging level for  semantic_kernel.kernel to DEBUG.\n",
    "    setup_logging()\n",
    "    logging.getLogger(\"kernel\").setLevel(logging.DEBUG)\n",
    "\n",
    "    # Add BigQuery plugin\n",
    "    bq_plugin = BigQueryPlugin(\n",
    "        project_id=\"colas-training\",\n",
    "        dataset_id=\"colas_data\"  # Optional default dataset\n",
    "    )\n",
    "    kernel.add_plugin(\n",
    "        bq_plugin,\n",
    "        plugin_name=\"BigQuery\"\n",
    "    )\n",
    "\n",
    "    # Enable planning\n",
    "    execution_settings = AzureChatPromptExecutionSettings()\n",
    "    execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "    # Create a history of the conversation\n",
    "    history = ChatHistory()\n",
    "\n",
    "    # Initiate a back-and-forth chat\n",
    "    userInput = None\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        userInput = input(\"User > \")\n",
    "\n",
    "        # Terminate the loop if the user says \"exit\"\n",
    "        if userInput == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Add user input to the history\n",
    "        history.add_user_message(userInput)\n",
    "\n",
    "        # Get the response from the AI\n",
    "        result = await chat_completion.get_chat_message_content(\n",
    "            chat_history=history,\n",
    "            settings=execution_settings,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Assistant > \" + str(result))\n",
    "\n",
    "        # Add the message from the agent to the chat history\n",
    "        history.add_message(result)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
